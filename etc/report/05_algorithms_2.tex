\section{Algorithm classes}

The algorithms studied and discussed in the theoretical section all share the same structure, so we decided to build an abstract class for a generic Gibbs sampling iterative BNP algorithm, the \verb|Algorithm| class:
\begin{verbatim}
template<template <class> class Hierarchy, class Hypers,
         class Mixture> class Algorithm
\end{verbatim}
All algorithms of this form can be built as derived classes from this one.
It is constructed by the following function:
\begin{verbatim}
Algorithm(const Hypers &hypers_, const Mixture &mixture_,
    const Eigen::MatrixXd &data_, const unsigned int init = 0);
\end{verbatim}
As mentioned, the first argument initializes the passed \verb|Hypers| object through a shared pointer.
\verb|init| is assigned to the \verb|init_num_clusters| member, which states the number of clusters in the initialization phase of the algorithm.
If a value is not provided, it will be set equal to the data size in the constructor body, therefore placing one object in each cluster. \\
The \verb|Algorithm| class contains the integer class members \verb|maxiter|, the cumulative number of algorithm iterations, and \verb|burnin|, the number of initial iterations in the burn-in phase, which will be discarded.
These integer values, including the seed for the \verb|rng| object (of type \verb|std::mt19937|, a basic Mersenne Twister random number generator provided by the standard C++ library) and the \verb|n_aux| parameter that indicates the number of auxiliary blocks in \verb|Neal8|, are not present in the class constructor since they are usually left with their default values, though they can still be changed through their respective setters.
If no other values are provided, \verb|maxiter| is initialized to 1000, \verb|burnin| to 100, and \verb|n_aux| to 3, values that we have assessed as sufficient for a good approximation after performing several tests.
Note that changing these values after running the algorithm (see below for the \verb|run()| function) has no effect as far as the execution of the algorithm is concerned. \\
Moreover, the class contains several data and values containers:
\begin{verbatim}
Eigen::MatrixXd data;
std::vector<unsigned int> cardinalities;
std::vector<unsigned int> allocations;
std::vector< Hierarchy<Hypers> > unique_values;
std::pair< Eigen::MatrixXd, Eigen::VectorXd > density;
Mixture mixture;
State best_clust;
\end{verbatim}
The matrix of row-vectorial data points is given as input to the class constructor by the user.
Data points were chosen to be matrix rows, even though points in a space are usually represented as column vectors, because this is the way data are usually stored in comma- or space-separated values files.
In fact, the \verb|utils.hpp| file contains the \verb|read_eigen_matrix()| utility, which returns an \verb|Eigen::MatrixXd| after reading values from a given filename.
This works for both data matrices and grid matrices on which evaluate the estimated density (see section \ref{estimates-imp} for the implementation details). \\
The algorithm will keep track of the labels representing assignments to clusters via the \verb|allocations| vector.
For instance, if at any point one has \verb|allocations[5] = 2|, it means that datum number 5 is associated to cluster number 2, with indexing starting at zero.
Similarly, we store the \verb|cardinalities| of the current clusters and \verb|unique_values|, which is a vector of Hierarchy objects which identify the clusters and in which the corresponding unique values are stored in the \verb|state|, as mentioned in the previous section.
The three aforementioned vectors are initialized with null values and empty \verb|Hierarchy| objects, and will be filled with proper values while the algorithm is running. \\
The \verb|run()| method is the same from all derived classes, given that all implemented algorithms share the same general structure:
\begin{verbatim}
void step(){
    sample_allocations();
    sample_unique_values();
    sample_weights();
    update_hypers();
}

void run(BaseCollector* collector){
    initialize();
    unsigned int iter = 0;
    collector->start();
    while(iter < maxiter){
        step();
        if(iter >= burnin){
            save_state(collector, iter);
        }
        iter++;
    }
    collector->finish();
}    
\end{verbatim}
That is, a Gibbs sampling iterative BNP algorithm generates a Markov chain on the clustering of the provided data running multiple iterations of the same \verb|step()|.
The latter is further split into substeps, each of which updates specific values of the state of the Markov chain, which we recall to be composed of the allocations vector and the unique values vector.
Substeps are then overridden in the specific derived classes.
In particular, among the studied algorithms, only the currently unimplemented blocked Gibbs algorithm exploits the \verb|sample_weights()| function.
Moreover, \verb|update_hypers()| only has an effect when the hyperparameters are not fixed.
Therefore this function is not currently used in the library either, since we only have \verb|Hypers| classes representing fixed ones at the moment.
The collector argument of \verb|run()| and the functions \verb|start()|, \verb|save_state()|, and \verb|finish()| deal with storage of the chain state, which we will discuss later in the appropriate section \ref{collectors}. \\
We shall now describe the features of the two implemented derived classes: \verb|Neal2| and \verb|Neal8|.

\subsection{\texttt{Neal2}}
As discussed in section \ref{neal2}, the \verb|Neal2| algorithm exploits conjugacy, thus the class requires specifically implemented hierarchies, in which the marginal distribution of the data with respect to $\boldsymbol\theta$ is provided in closed form.
In our case, the Normal-NIG and Normal-NW specializations for the \verb|Neal2| template class were implemented.

The \verb|Neal2| class implements the substeps of the \verb|run| in the following manner:

\begin{itemize}
	\item In \verb|initialize()|, a number of clusters equal to the provided initial valued are created and data are randomly assigned to them, while making sure that each cluster contains at least one.
	Assignment to a cluster means that the \verb|allocations| component of the datum is set equal to the number of the cluster, as explained earlier.

	\item In \verb|sample_allocations()|, a loop is performed over all observations $i=1:n$.
	The vector \verb|cardinalities| is filled at first, with \verb|cardinalities[j]| being the cardinality of cluster $j$.
	Then, the algorithm mandates that \verb|datum = data.row(i)| be moved to another cluster;
	A vector \verb|probas| with \verb|n_clust| components if \verb|datum| belongs to a cluster that is a singleton, or with \verb|n_clust+1| otherwise, is filled with the probabilities of each $\boldsymbol\phi$ being extracted, in line with (\ref{probasneal2}).
	Computations involve the \verb|cardinalities| vector, the mass probabilities defined by the \verb|Mixture|, the likelihood \verb|like()| evaluated in \verb|datum| to compute the probability of being assigned to an already existing cluster and \verb|eval_marg()| to compute the probability of being assigned to a newly generated cluster. Then, the new value for \verb|allocations[i]| is randomly drawn according to the computed \verb|probas|.
	Finally, four different cases of updating \verb|unique_values| and \verb|cardinalities| are handled separately, depending on whether the old cluster was a singleton or not and whether \verb|datum| is assigned to a new cluster.
	Indeed, in such a case, a new $\boldsymbol\phi$ value for it must be generated, and this must be handled differently by the code if an old singleton cluster was just destroyed (as the new cluster must take its former place).
	Depending on the case, clusters are either unchanged, increased by one, decreased by one, or moved around.

	\item In \verb|sample_unique_values()|, for each cluster $j$, their $\boldsymbol\phi$ values are updated through the \verb|sample_given_data()| function, which takes as argument the vector \verb|curr_data| of data points which belong to cluster $j$.
	Since we only keep track of clusters via their labels in \verb|allocations|, we do not have a vector of actual data points stored for each cluster.
	Thus we must fill, before the loop on $j$, a matrix \verb|clust_idxs| whose column $k$ contains the index of data points belonging to cluster $k$.
	\verb|clust_idxs| is then used in the $j$ loop to fill \verb|curr_data| with the actual data points of cluster $j$.

\end{itemize}


\subsection{\texttt{Neal8}}

Being Neal's algorithm 8 a generalization of Neal's algorithm 2 which works for any hierarchical model, even non-conjugate ones, it adds adjustments in the allocation sampling phase to circumvent non-conjugacy.
However, the unique values sampling phase remains unchanged. For this reason \verb|Neal8| is built as a derived class from \verb|Neal2|.

In addition to the members defined in Algorithm, the following are added in Neal8 class:
\begin{verbatim}
unsigned int n_aux = 3;
std::vector<Hierarchy<Hypers>> aux_unique_values;
\end{verbatim}
These are related to the auxiliary blocks. In particular the number of auxiliary blocks is automatically set equal to 3 with the possibility to change the default value with the corresponding setter.

Relying on the algorithm described in section \ref{neal8}, we proceed to describe the implementation of \verb|sample_allocations()|.

As before, a loop is performed over all observations $i=1:n$ and \verb|cardinalities| is filled. Now, if the current cluster is a singleton, its $\boldsymbol\phi$ values are transferred to the first auxiliary block. Then, each auxiliary block (except the first one if the above case occurred) generates new $\boldsymbol\phi$ values via the hierarchy's \verb|draw()| function. Now a new cluster, that is, new $\boldsymbol\phi$ values, for \verb|datum| needs to be drawn. 	A vector \verb|probas| with \verb|n_clust+n_aux| components is filled with the probabilities of each $\boldsymbol\phi$ being extracted, in line with (\ref{neal8prob}). In this case computations involve also the auxiliary components. Then,as in \verb|Neal2|, the new value for \verb|allocations[i]| is randomly drawn according to the computed \verb|probas|. Finally, four different cases of updating \verb|unique_values| and \verb|cardinalities| are handled separately, depending on whether the old cluster was a singleton or not, and whether an auxiliary block or an already existing cluster was chosen as the new cluster for \verb|datum|.
