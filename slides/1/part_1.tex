%\begin{frame}[c]
%	\begin{center}
%		\Huge \color{blue} Title
%	\end{center}
%\end{frame}


\begin{frame}
	\frametitle{Non-Parametric Statistics}
	\begin{itemize}
		\item Goal: density estimation
		\item \textbf{Infinite-dimensional} parameters
		\item For example: functions
		\item Bayesian Non-Parametric (\textbf{BNP}) model:
		\begin{align*}
			y_i | G &\iidsim G, \quad i=1,\dots,n \\
			G &\sim \mathscr P \ \ \text{($G$ random pr. measure)} %\\[10pt]
			%\mathscr P : \Omega &\to M(S)
		\end{align*}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Dirichlet Process Prior}
	\begin{align*}
		y_i | G &\iidsim G, \quad i=1,\dots,n \\
		G &\sim \mathscr P = \mathscr{DP}(M G_0)
	\end{align*}
	\vspace{-10pt}
	\begin{itemize}
		\item Parameters: $M > 0, \ G_0 \in M(S)$
		\vspace{5pt}
		\item Defining property: $\forall \{B_{1:k}\}$ partition of $S$,
		$$[G(B_1),\dots,G(B_k)] \sim \operatorname{Dir}
			\big( M G_0(B_1),\dots, M G_0(B_k) \big)$$
		\vspace{-15pt}
		\item \textbf{Discreteness} (stick-breaking): $G(\cdot) = \sum_{k=1}^{+\infty} w_k \delta_{m_k} (\cdot)$
		\vspace{10pt}
		\item \textbf{Conjugacy}: $G | \mathbf{y} \sim \mathscr{DP}(M G_0 + \sum_{i=1}^n \delta_{y_i}) \ \implies$ density estimation
%		\item Polya urn representation:
%		\begin{center}
%			$ \Lc(y_i | y_1,\dots,y_{i-1}) \propto \sum_{h=1}^{i-1} \delta_{y_h}(y_i) + M G_0 (y_i) $
%		\end{center}
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Continuous Density Estimation}
	\begin{itemize}
		\item \textbf{Mixtures} (kernel $F$ + mixing distribution $G$):
		\begin{align*}
			y_i | G &\sim F_G(y) = \int F(y,\theta) \, G(\de\theta), \quad i=1,\dots,n \\
			G &\sim \mathscr{DP}(M G_0)
		\end{align*}
		\vspace{-10pt}
		\item Model name: Dirichlet-Process Mixture (\textbf{DPM}) model
		\item Equivalent to a hierarchical model:
		\begin{align*}
			y_i | \theta_i &\indsim F(\cdot,\theta_i), \quad i=1,\dots,n \\
			\theta_i | G &\iidsim G, \quad i=1,\dots,n \\
			G &\sim \mathscr{DP}(M G_0)
		\end{align*}
		\item $\theta_i$ \textit{latent variables}, one per unit
	\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Clustering In The DPM}
	\begin{itemize}
		\item Discreteness: the $\theta_i$ have one of $k$ \textbf{unique values} $\phi_j$ %TODO why are the \phi finite?
		\item Data units: $i=1,\dots,n$ \\
		\item Unique values: $j=1,\dots,k \simeq M \log n \ll n$
		\item $c_i$ \textbf{allocation} parameters to the clusters: $c_i = j$ if $\theta_i = \phi_j$
		\pause
		\item Conditional prior for $\theta_i$, $i=1,\dots,n$:
		\vspace{-5pt}
			\begin{minipage}{0.3\textwidth}
				\begin{align*}
					\hspace{-10pt}
					\Lc(\theta_i | \boldsymbol\theta_{-i}) \propto
					\sum_{j=1}^{k^-} n^-_j &\delta_{\phi^-_j} (\theta_i) + M G_0 (\theta_i) \\
					&\uparrow \hspace{55pt} \uparrow
				\end{align*}
			\end{minipage}%
			\begin{minipage}{0.5\textwidth}
				\include{etc/diffuse_spiked}
			\end{minipage}
		\vspace{-5pt}
		\item Conditional posterior for $\theta_i$:
		$$ \Lc(\theta_i | \boldsymbol\theta_{-i}, y_i) \propto
		\sum_{j=1}^{k^-} F(y_i,\theta) \, \delta_{\phi^-_j} (\theta_i) + M \, r_i \, G_0(\theta_i | y_i) $$ %\int f_{\theta_j}(y_i) \, G_0 (\de\theta)
	\end{itemize}
\end{frame}


\begin{frame} %#03
	\frametitle{Discrete Model}
	\begin{figure}[htpb] 
		\minipage{0.40\textwidth}
    	    \begin{align*}
  	 		    (Y_{i}|\theta_{i})&\sim F(\cdot,\theta_i) \\
    	        (\theta_{i}|G)&\sim G \\
            	G & \sim \mathscr{DP}(M,G_{0}) \\
      		\end{align*}
        	\begin{center}
        		(hierarchical model)
        	\end{center}
		\endminipage 
		%\hspace{1cm}
		\minipage{0.10\textwidth}
			$\stackrel{K\to\infty}{\iff}$
		\endminipage
		\minipage{0.40\textwidth} 
        	\begin{align*}
            	(Y_{i}|\mathbf{\phi},c_{i})&\sim F(\cdot,\phi_{c_{i}}) \\
            	(c_{i}|\mathit{\mathbf{p}})&\sim \sum_{k=1}^K\mathit{p_k} \delta_k(\cdot) \\
            	\phi_{c} & \sim G_{0} \\
            	\mathbf{p} &\sim \operatorname{Dir}(M/K,\dots,M/K)
        	\end{align*}
        	\begin{center}
        		($K$-discrete model)
        	\end{center}
		\endminipage  
	\end{figure}
	\begin{center}
		$$\text{with} \quad \boldsymbol\theta \leftrightsquigarrow (\boldsymbol\phi, \mathbf c)$$
	\end{center}
\end{frame}




\begin{frame} %#04
	\frametitle{Neal's Algorithm 2}
	\textbf{Gibbs sampling} algorithm:
	\begin{itemize}
		\item $(\boldsymbol\phi, \mathbf c)$ is the \textbf{state} of a Markov chain
	    \item For $i= 1,\dots,n$: update $c_{i}$
	    \begin{itemize}
	        \item If $c_{i}$ allocates $\phi_{c_i}$ to a singleton, remove $\phi_{c_{i}}$ from the state
		    \item Sample $c_i$ as follows:
	        \begin{align*}
		        \hspace{-35pt}
                \text{If $c=c_j$ for some $j\neq i$: } \PP(c_{i}=c | \mathbf c_{-i}, y_{i},\boldsymbol\phi) &\propto \frac{n_{-i,c}}{n-1-M} F(y_{i},\phi_{c}) \\
                \text{total } \ \PP(c_{i}\neq c_{j} \text{ for all } j | \mathbf c_{-i}, y_{i},\boldsymbol\phi) &\propto \frac{M }{n-1-M} \int F(y_{i},\phi) \, G_0(\de\phi)
            \end{align*}
            \item If the new $c_{i}$ allocates $\phi_{c_i}$ to a singleton, draw $\phi_{c_{i}} \sim G_0(\cdot|y_i)$ and add it to the state
        \end{itemize} 
        
       	\item For $c \in \{c_{1},\dots,c_{n}\}$: update $\phi_{c}$, given all the $y_{i}$ with $c_{i}=c$
	\end{itemize}
		
\end{frame}


%\begin{frame}
%	\frametitle{Advantages}
%	\begin{itemize}
%	    \item Feasible if we can compute the $\int F(y_i,\phi) G_0(\de\phi)$ and sample from the $G_0(\cdot|y_i)$ (conjugate case)
%	    \item Change the $\theta$ for more than one observation simultaneously
%	\end{itemize}
%\end{frame}


%\begin{frame}
%	\frametitle{Title}
%	\begin{itemize}
%		\item Text
%	\end{itemize}
%\end{frame}
