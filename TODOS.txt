TODO LIST


CHANGELOG
* Sistemata faccenda totalmass
* Creata classe BaseMixture
* Aggiunta cluster_estimate2() che usa le Sparse Matrix
* Rimosso colltype dall'interfaccia Python (tanto ha senso usare solo il file
  collector)
* Aggiunto n_aux all'interfaccia Python
* Di conseguenza, aggiunto set_n_aux() anche alla classe base Algorithm per
  ragioni di polimorfismo (in quella classe la funzione non fa nulla)


TESTS
* Univariati:
1) y_i ~ 0.5 N(-3, 1) + 0.5 N(3, 1), i=1,... 200
   mu_0 = 0.0
   lambda = 0.1 (o 10, dipende dalla parametrizzazione)
   a, b = 2 (parametri della inv-gamma)
2) y_i ~ 0.9 N(-5, 1) + 0.1 N(5, 1), i=1,... 1000
   stessi parametri di prima
3) y_i ~ 0.3 N(-2, 0.8^2) + 0.3 N(0, 0.8^2) + 0.4 N(2, 1) i=1,... 200
4) y_i ~ 0.5 t(5, -5, 1 ) + 0.5 SkewNormal(2, -5, 1) i=1,... 400
   (per generare questi dati guardate il pacchetto python Scipy)

* Multivariati:
5) y_i ~ 0.5 N((-3, -3), I) + 0.5 N((3, 3), I) i=1, ... 400
6-8) dati come prima (media della prima componente mistura tutti -3, e della
     seconda tutti +3) all'aumentare della dimensione (d=2, 5, 10, 20)
     per dimensioni sopra il 10 non dovrebbe più funzionare granchè...
* plot delle densità stimate e densità vere
* riportate rand-index della partizione stimata (solo per dimensione 1 e 2,
  dovrebbe venire sempre alto tranne magari l'esempio con la t e SkewNormal, ma
  la densità dovrebbe venire bene uguale)


IMPLEMENTAZIONE
* row vs column data
* useless default constructors in classes
* NNIG has status sig or sig^2?
* dataless (see e.g. console.py)
* Test cluster_estimate() vs cluster_estimate2()
* Rename some files (output) and functions
* Move .proto files?
* (?) plot Python: highest posterior density intervals (credible intervals),
  arviz (library), contour plot


STILE
* Fix BNP models in algorithms and hierarchies
* grep -R "[^ ] $" src/*; spazi; a capo; etc
* Make Python files appear in the docs


VARI
* Redo callgrind and time stuff (optimization)
* Check all algorithm/hierarchy/mixture combinations, csv files, etc
* README (Virtual Machine etc)
* Ens doxygen docs



REPORT
* in inglese
* Introduzione bayes
** Polya urn: infinite variabili latenti
* parametri non nel costruttore solitamente sono lasciati in default
* a way to erase and add clusters more efficiently, e.g. with map
* storing cardinalities > recomputing them at each iteration
* set_state flag efficienza
* hyperparameters per la NNW: lambda piccolo (permette libertà), mu0 media
  empirica, nu = dim.dati + 3, sigma0 = tale che la sua media (nu * tau0) sia
  l'identità
* spiegare le flag di efficienza: -march=native -O3 -msse2 -funroll-loops
  -ftree-vectorize
* confronto delle performance con il pacchetto R 'BNPMix', per quanto riguarda
  i tempi computazionali. Attenti a che sampler scegliete in quel pacchetto: 
  di default usa uno slice sampler che non è molto efficiente, selezionate il
  sampler marginale ('MAR') e matchate gli iperparametri.


LIBRERIA (?)
* setup.py, niente Makefile
